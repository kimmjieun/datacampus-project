{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "허그데이터_LDA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiieunx/datacampus/blob/master/%ED%97%88%EA%B7%B8%EB%8D%B0%EC%9D%B4%ED%84%B0_LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-AmHGP3i0Vb"
      },
      "source": [
        "pip install pyLDAvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ilbiSDms_1L"
      },
      "source": [
        "!apt-get update \n",
        "!apt-get install g++ openjdk-8-jdk python-dev python3-dev \n",
        "!pip3 install JPype1-py3 \n",
        "!pip3 install konlpy\n",
        "\n",
        "!JAVA_HOME=\"C:\\Program Files\\Java\\jdk-14.0.2\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDLMr0Fki3SF"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        " \n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        " \n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        " \n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        " \n",
        " \n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        " \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0uD0DFfuXnB"
      },
      "source": [
        "from collections import Counter\n",
        "from konlpy.tag import Twitter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tKG89X9i7YM"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel('허그일자리.xlsx')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3i9RaZRo8hO"
      },
      "source": [
        "data = df.CONSULT_CONT.values.tolist()\n",
        "\n",
        " \n",
        "# Remove new line characters\n",
        "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
        " \n",
        "# Remove distracting single quotes\n",
        "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
        " \n",
        "pprint(data[:1])\n",
        "\n",
        "len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLTMn8niGaBM"
      },
      "source": [
        "!apt-get update \n",
        "!apt-get install g++ openjdk-8-jdk python-dev python3-dev \n",
        "!pip3 install JPype1-py3 \n",
        "!pip3 install konlpy\n",
        "\n",
        "!JAVA_HOME=\"C:\\Program Files\\Java\\jdk-14.0.2\"\n",
        "#해야함"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-njLfTvsFivi"
      },
      "source": [
        "!pip install customized_konlpy\n",
        "from ckonlpy.tag import Twitter\n",
        "\n",
        "from collections import Counter\n",
        "#from konlpy.tag import Twitter\n",
        "\n",
        "twt = Twitter()\n",
        "twt.add_dictionary(['허그일자리', '직업훈련', '사후관리', '취업알선','집단상담','경제적','안정적','긍정적','참여자','보호위원','허그일자리사업','구직활동','특이사항','적극적','위문물품','취업박람회','대형면허'], 'Noun') #사용자사전\n",
        "noun=[]\n",
        "\n",
        "dataset=[]\n",
        "\n",
        "for i in range(1350):\n",
        "  try:\n",
        "\n",
        "  \n",
        "    tmp=twt.nouns(data[i])\n",
        "    stopword=['통해','위해','대한','생으로','고취','다시','참석','맞이','수업','필요','시간','크게','중임','제적','실시','안내','대해','도록','까지','전함','이후','중이','로서','때문','매우','제대로','지금','또힌','자로','지난','오늘','자임','관리','지원','상태','결연','진행','가지','나눔','본인','행사','과정','금일','마련','향후','상황','이야기','위문물품','기반','면서','연락','예정',#의미없는말 \n",
        "              '허그','일자리','허그일자리사업','허그일자리','멘토링','집단상담','취업','참여','활동','현재','사업','참여자','대상자','보호위원','직업','생활','프로그램','수료식','취업박람회','성공','유선','관련', '모습','설명','훈련','명절','학과','근무','운전면허','입교',#활동이나 행사등 \n",
        "              '독려', '당부','격려','근속','확인','지속','자녀']# 상담자가 한말    \n",
        "   # stopword=['통해','위해','대한','생으로','고취','다시','맞이','크게','중임','대해','전함','이후','중이','로서','때문','매우','제대로','지금','또힌','자로','지난','오늘','자임','관리','지원','상태','결연','진행','가지','나눔','본인','행사','과정','금일', #의미없는말 \n",
        "          #    '허그','일자리','취업','멘토링','상담','참여','활동','현재','집단상담','훈련','사업','참여자','대상자','보호','직업','위원','생활','프로그램','수료식', #활동이나 행사등 \n",
        "           #   '독려', '당부','격려']# 상담자가 한말    \n",
        "\n",
        "    #stopword=['통해','위해','대한','생으로','고취','다시','맞이','크게','중임','대해','전함','이후','중이','로서','때문','매우','제대로','지금','또힌','자로','지난','오늘','자임','관리','지원','상태','결연','진행','가지','나눔','본인','행사','과정','금일', #의미없는말 \n",
        "    #          '허그','일자리','멘토링','활동','현재','사업','참여자','대상자','생활', #활동이나 행사등 \n",
        "     #         '독려', '당부','격려']# 상담자가 한말  \n",
        "              #활동 빼면 안될것같다 그 활동에 대한 내용어쨌는지 나와야하니까 넣을 활동과 ㅎ뺄활동 정하기 \n",
        "    noun += [x for x in tmp if len(x)>1 if x not in stopword]\n",
        "    dataset.append(noun)\n",
        "    #noun += [x for x in tmp if len(x)>1]\n",
        "\n",
        "  except:\n",
        "    print('except')\n",
        "            \n",
        "#java.lang.NullPointerException: java.lang.NullPointerException"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWB7DjXaITH_"
      },
      "source": [
        "#data_lemmatized=[dataset]\n",
        "data_lemmatized=dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CunRvwfmHYU-"
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        " \n",
        "# Create Corpus\n",
        "texts =  data_lemmatized\n",
        " \n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        " \n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqcJcx6RIxRN"
      },
      "source": [
        "\n",
        "id2word[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7yCjFZgI8kH"
      },
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KO6swCLI_2y"
      },
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "id2word=id2word,\n",
        "num_topics=10,\n",
        "random_state=100,\n",
        "update_every=1,\n",
        "chunksize=100,\n",
        "passes=10,\n",
        "alpha='auto',\n",
        "per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMRPamPIywE"
      },
      "source": [
        "\n",
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYp8wxjoJGXd"
      },
      "source": [
        "\n",
        " \n",
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus)) # a measure of how good the model is. lower the better.\n",
        " \n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5jn8JXlJJVU"
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
        "vis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ0joatUXjTi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}