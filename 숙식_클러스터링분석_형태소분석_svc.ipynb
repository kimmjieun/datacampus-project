{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "클러스터링분석_형태소분석_svc.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GA0PvUiEhZ3s",
        "PIW6xkIMhDvz",
        "EILurWKwhFvQ",
        "D0zOgNxmJfed",
        "fyx8VCnfGT8c",
        "J8CpGk_lYVVY",
        "vuSHc1cwGxXU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiieunx/datacampus/blob/master/%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EB%A7%81_%ED%98%95%ED%83%9C%EC%86%8C%EB%B6%84%EC%84%9D%EC%99%84%EB%A3%8C_svc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA0PvUiEhZ3s"
      },
      "source": [
        "#그래프 한글깨짐 방지"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_sGdeMZhfQo"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "!apt -qq -y install fonts-nanum\n",
        " \n",
        "import matplotlib.font_manager as fm\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager._rebuild()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYB1cAOWhhtu"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.plot([0,1], [0,1], label='한글테스트용')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIW6xkIMhDvz"
      },
      "source": [
        "# 설치 및 패키지"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqQni4QEhFUt"
      },
      "source": [
        "!apt-get update\n",
        "\n",
        "!apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "\n",
        "!pip3 install JPype1-py3\n",
        "\n",
        "!pip3 install konlpy\n",
        "\n",
        "!JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r_e34vxhFSL"
      },
      "source": [
        "import pandas as pd #판다스 패키지 불러오기\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud \n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action = 'ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw0mhAg2hFKf"
      },
      "source": [
        "import jpype\n",
        "print(jpype.isJVMStarted()) #return False:not running or 0:running"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuoIvalAhOUD"
      },
      "source": [
        "!pip install customized_konlpy\n",
        "from konlpy.tag import Twitter \n",
        "from ckonlpy.tag import Twitter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORQmS8VlhPcd"
      },
      "source": [
        "# 일단 import \n",
        "%matplotlib inline  \n",
        "import matplotlib as mpl  # 기본 설정 만지는 용도\n",
        "import matplotlib.pyplot as plt  # 그래프 그리는 용도\n",
        "import matplotlib.font_manager as fm  # 폰트 관련 용도"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuol6FNPhQlQ"
      },
      "source": [
        "#나눔고딕인스톨\n",
        "!apt-get update -qq\n",
        "!apt-get install fonts-nanum* -qq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2ysVm8mhRwn"
      },
      "source": [
        "# 체크해보면 폰트 개수가 늘어났다\n",
        "sys_font=fm.findSystemFonts()\n",
        "print(f\"sys_font number: {len(sys_font)}\")\n",
        "\n",
        "nanum_font = [f for f in sys_font if 'Nanum' in f]\n",
        "print(f\"nanum_font number: {len(nanum_font)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6m113ZhhTBr"
      },
      "source": [
        "# 현재 설정되어 있는 폰트 사이즈와 글꼴을 알아보자\n",
        "!python --version\n",
        "def current_font():\n",
        "  print(f\"설정 폰트 글꼴: {plt.rcParams['font.family']}, 설정 폰트 사이즈: {plt.rcParams['font.size']}\")  # 파이썬 3.6 이상 사용가능하다\n",
        "        \n",
        "current_font()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69DTeJUbhTF2"
      },
      "source": [
        "path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'  # 설치된 나눔글꼴중 원하는 녀석의 전체 경로를 가져오자\n",
        "font_name = fm.FontProperties(fname=path, size=10).get_name()\n",
        "print(font_name)\n",
        "plt.rc('font', family=font_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EILurWKwhFvQ"
      },
      "source": [
        "#데이터 작업"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGmHNFkg-aUj"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('data2_5.xlsx')\n",
        "df.head(3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHtHRsc-IlxL"
      },
      "source": [
        "df = df[df['CARE_OPEN_CLASS_NM']==10]\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOV4TClvJSID"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJSxULQuGH3h"
      },
      "source": [
        "#Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0zOgNxmJfed"
      },
      "source": [
        "##전처리 불용어 재처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV2JGliwJdUb"
      },
      "source": [
        "twitter = Twitter() \n",
        "twitter.add_dictionary(['허그집단프로그램','담당직원','사회복귀','당직자', '숙식보호', '직업훈련', '적극적', '보호관찰', '프로그램 종료', '지원이유', '지금', '특별한사항', '이행사항', '용접기술교육원', '취업알선', '특수용접기능사', '유의사항', '취업박람회', '허그일자리프로그램', '건강관리', '긴급원호', '상기 인', '야간반', '여성기술교육원', '용접배관', '주거지원자', '가족관계', '허그일자리지원프로그램', '고용보험', '상기자', '영농기술교육원', '안전사고', '안정적', '준수사항', '보호종료', '취업지원 프로그램', '구직활동', '대형면허', '건축도장기능사', '건강문제', '친구들', '거주지', '집단상담', '시설관리직', '필기합격', '긍정적', '주거지원', '출결관리', '가족부양', '참여자', '허그 일자리 프로그램', '전기기술교육원', '이행상황', '자기관리', '기술교육원', '기초수급자', '정산금', '특이사항', '애로사항', '용접기능사', '사후관리', '보호관찰법', '기계가공기술교육원', '지원기회', '보호사업', '보호관찰소', '생활 준칙', '위문물품', '법무보호가족교육원', '실기합격', '주거지', '지출관리', '외출 요청', '예치금', '생활관 준칙', '합동결혼식', '용접기능훈련', '미납금', '상기 대상자', '사회성향상 프로그램', '규칙적', '가족희망센터', '몸관리', '상기인', '보호관찰소장', '안전관리', '경제적', '입주자', '취업성공패키지', '보호위원', '허그일자리 프로그램', '허그일자리사업', '집단프로그램', '기초수급', '장기간', '허그 일자리 집단프로그램', '보호종료자', '자동차정비기술교육원', '허그일자리', '식구들', '변동사항', '생활관준칙', '용접훈련', '자립이행상황통보서'], 'Noun')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvTgyyk2Jp31"
      },
      "source": [
        "#불용어 처리\n",
        "#날짜 계정 등 시기를 나타내는 단어\n",
        "stopwords= [ #날짜 계정 등 시기를 나타내는 토큰\n",
        "        '개월','금일', '기간','겨울','년도', '날짜','금월','까지', '날씨', '어제', '이번','지금','최근', '추후','하루', '한번', '항상','현재','시일','오늘','조기','그동안',\n",
        "        '다음주','평소','차후','지난','요즘','아침','오전','오후','예전','한해','전일','여름','시기', '가끔','사이','최종','명일','향후',\n",
        "\n",
        "        #지역 위치나타내는 토큰\n",
        "        '경기도','김해','서울','울산','천안',\n",
        "        \n",
        "        #관련없는 토큰\n",
        "        '격려', '결과', '경우', '계속', '계획', '공단', '과정', '관련', '관리','근황','기관','보호', '본인','다른', '다소', '다시', '다음', '담당', '담당자', '당부','실시',\n",
        "        '대상자', '독려',  '마련','멘토링','문자', '문제', '발생', '방문', '보고','상기인', '상담', '상태', '상황', '생활', '생활관', '소하', '숙식', '스스로', '시간','주거',\n",
        "        '아직', '여건', '연락', '예정', '외박', '외출', '요청','유의','이야기', '이행','이후', '입소', '자신', '작성','전화','정리', '정적', '제공', '제출', '조치', '종료',\n",
        "        '주거지', '주거지원', '준비','지도','지원', '지지', '직원', '진행', '참여', '처리','통보','퇴소','확인', '활동','변경','가능','일부','심사','결정','전환','강조',\n",
        "        '보호종료','개시','동일','파악','재차','사용','주기','연결','마무리', '사실','기재','얼마','의사','사료','변동','참여자','기타','단계','완료', '귀하','혼자','당장',\n",
        "        '해당','해지','인계','각종', '번호','취지','참고','보도','약간','대신','진단','물음','회의','양해','완전','유선','부분','만료','상기 대상자','상기자','패키지','가장',\n",
        "\n",
        "        #쓸모없는 토큰\n",
        "        '가지','고자', '고함','구들', '금은','기반', '기하','동안', '되어', '드림', '때문', '또한', '려고', '로부터','다해' ,'대하', '대한', '대해', '더욱', '도로', '도록',\n",
        "        '만원', '만큼' , '면서', '모습', '문하', '바로',  '보이', '보임','부분계획', '부터', '부하', '사항', '상기', '않아', '양곡','어서','위해', '유의면서','이행상',\n",
        "        '인의', '인하','있는', '있다고', '있도록', '있어', '있으며', '있음', '자로','전하', '전함','정도','중이', '중임', '지부', '지소', '통해','특이', '하겠다고', '하고',\n",
        "        '하고자', '하기', '하는', '하도록','하며', '하면서', '하여', '하였으며', '하였음', '하자', '하지','해주','통한','다가','처럼','하라','주지','무하','더라도','요하',\n",
        "        '여부','중인','달라', '물어','어가','상의','고하','라하','대로','어보','지고','이하','한지','각하','영하','알리','여러','바란','아무','이제','서도','당하','여서',\n",
        "        '립하','보기','로서','도래','지원이','남지','가기','지원기','조리','간다','만하','주어','시킴', '리지','아지','고용보', '족하','어도','성하','교하','일이','기해',\n",
        "        '일해','해하','달이','결하','조성하','제하','장일','도중','소가','심해','일어','일도','을시','도록','시운전'\n",
        "        # #청소년 관련 단어 \n",
        "        # \"학생\",\"징계\",\"친구\",\"선생님\",\"잘못\",\"청소년\",\"태도\",\"핸드폰\",\"아버지\",\"프로그램\",\"광주\",\"보호관찰소\",\n",
        "        # \"가정법원\",\"처분\",\"취침\",\"시경\",\"학교\",\"보호자\",\"검정고시\",\"무단\",\"언니\",\"무단이탈\",\"금지\",\"허락\",\"사건\",\n",
        "        # \"합격\",\"친구들\",\"미래\",\"반성\",\"동행\",\"보호처분\",\"이유\",\"사고\",\"야간\",\"청소\",\"감정\",\"위반\",\"남자친구\",\n",
        "        # \"보호관찰\",\"제한\",\"출석\",\"등교\",\"자녀\",\"고등학교\",\"아이\",\"표현\",\"학업\",\"지시\",\"인지\",'신청','저축', '일자리', '건강관리'#,\"전화\", '연락'\n",
        "        ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9KBFqvrJq_l"
      },
      "source": [
        "from ckonlpy.tag import Postprocessor\n",
        "#\n",
        "replace = {'주거지':'거주지' , \"행동\":\"태도\", \"애로\":\"특이\",\"주의\":\"유의\", \"상황\":\"상태\",\"열심\":\"성실\", \"불편\":\"어려움\", \"관리\":\"조치\", \n",
        "           '근로':'근무', '근속':'근무', '주의':'유의', '지지':'독려', '격려':'독려', '열심':'노력', '애로':'필요', '어려움':'문제', \n",
        "           '하라':'독려','의지':'노력', '지부':'공단', '지금':'현재', '회사':'일자리', '오늘':'현재',\n",
        "            \"전화\":\"통화\", \"통화\":\"연락\",\"유선\":\"연락\"}\n",
        "postprocessor = Postprocessor(twitter, replace = replace, passtags = 'Noun', stopwords = stopwords) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyx8VCnfGT8c"
      },
      "source": [
        "##트위터유저데이터, PRETRAINED W2V"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5MVXsJeGShj"
      },
      "source": [
        "!curl gdrive.sh | bash -s 13fQZtkz4SSzVNcqh73SBqnUDw2mSDgzL\n",
        "!curl gdrive.sh | bash -s 1W8u9ZuEhKCkTbaGLzUF4YcF2F_hYeE1B\n",
        "!curl gdrive.sh | bash -s 1GffvAF3tBtSpjsblIdP1Tcv25XEyBewm\n",
        "!curl gdrive.sh | bash -s 103jom7lxjiqQptIRjrIdSjXR8jRqrlEd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k_GrxK8Ge6b"
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCzRlA08Ggyw"
      },
      "source": [
        "# w2v모델 불러오기 \n",
        "model = Word2Vec.load('embedding.save')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSYF8jLhGl3w"
      },
      "source": [
        "#명사, 두글자이상 추출\n",
        "def get_tokens(x):\n",
        "    try:\n",
        "        return [i for i in postprocessor.pos(x) if len(i) > 1] if x else []\n",
        "    except Exception as e:\n",
        "        if str(x) == 'nan':\n",
        "            return []\n",
        "        print(e)\n",
        "        print(str(x))\n",
        "        raise e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp_yLM1SGozX"
      },
      "source": [
        "df['user_twtt'] = df['CONSULT_CONT'].map(get_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8CpGk_lYVVY"
      },
      "source": [
        "##'noun'제거 및 데이터프레임에 추가."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCenICcoSDn8"
      },
      "source": [
        "nouns = []\n",
        "for i in range(0,93390):\n",
        "  words = [n for n, tag in df['user_twtt'].tolist()[i] if tag == 'Noun']\n",
        "  nouns.append(words)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcjlzVq-YmXh"
      },
      "source": [
        "df = df.assign(user_twtt=nouns)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXgG970WZTIr"
      },
      "source": [
        "df['user_twtt_len'] = df['user_twtt'].map(len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7qX-iLhZB0X"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuSHc1cwGxXU"
      },
      "source": [
        "## 명사수 5개 이상인 유저만 추출 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s81HX2mGzjs"
      },
      "source": [
        "#명사 5개이상 추출 \n",
        "df['user_twtt_len'].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzrQu11DG1ER"
      },
      "source": [
        "bio_exists_df = df[df['user_twtt_len'] >= 25]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytW7qtWkG2fn"
      },
      "source": [
        "len(bio_exists_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dsSQ99dHFGe"
      },
      "source": [
        "bio_exists_df.sample(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELndcwJLHIC5"
      },
      "source": [
        "##유저의 벡터 = 각명사들 벡터의 MEAN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h74EtpZWHGA4"
      },
      "source": [
        "#문맥이해하는 더 좋은 방법 적용 \n",
        "def get_sentence_mean_vector(morphs):\n",
        "    vector = []\n",
        "    for i in morphs:\n",
        "        try:\n",
        "            vector.append(model.wv[i])\n",
        "        except KeyError as e:\n",
        "            pass\n",
        "    try:\n",
        "        return np.mean(vector, axis=0)\n",
        "    except IndexError as e:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7xdNTSMHMbr"
      },
      "source": [
        "bio_exists_df['wv'] = bio_exists_df['user_twtt'].map(get_sentence_mean_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbv1GFeNHQyw"
      },
      "source": [
        "##300차원벡터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGFva2oGHOKn"
      },
      "source": [
        "len(bio_exists_df.dropna().head(1)['wv'].to_list()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG0Vyz3pHWPp"
      },
      "source": [
        "##빈것 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBVt9nOkHXfR"
      },
      "source": [
        "bio_exists_df = bio_exists_df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjCg4JPkHYoW"
      },
      "source": [
        "len(bio_exists_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-92_mroOHcCC"
      },
      "source": [
        "#KMEANS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45r6LOYnNHYI"
      },
      "source": [
        "###클러스터링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjUPp98fQSHT"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bDgi6I5cQSZ"
      },
      "source": [
        "word_vectors = bio_exists_df.wv.to_list() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2VJIRruh9kb"
      },
      "source": [
        "start = time.time() # 시작시간\n",
        "\n",
        "word_vectors = bio_exists_df.wv.to_list() \n",
        "num_clusters = 40\n",
        "\n",
        "# K means 를 정의하고 학습시킨다.\n",
        "kmeans_clustering = KMeans( n_clusters = num_clusters )\n",
        "idx = kmeans_clustering.fit_predict( word_vectors )\n",
        "bio_exists_df['category'] = idx\n",
        "\n",
        "# 끝난 시간에서 시작시각을 빼서 걸린 시간을 구한다.\n",
        "end = time.time()\n",
        "elapsed = end - start\n",
        "print(\"Time taken for K Means clustering: \", elapsed, \"seconds.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM5PcTpe7uYS"
      },
      "source": [
        "bio_exists_df.to_excel('클러스터링3.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SulshXEQcvk1"
      },
      "source": [
        "word_vectors = bio_exists_df.wv.to_list() \n",
        "\n",
        "def elbow(X):\n",
        "    sse = []\n",
        "\n",
        "    for i in range(10,51):\n",
        "        km = KMeans(n_clusters=i,algorithm='auto', random_state=42)\n",
        "        km.fit(word_vectors)\n",
        "        sse.append(km.inertia_)\n",
        "\n",
        "    plt.plot(range(10,51), sse, marker='o')\n",
        "    plt.xlabel('K')\n",
        "    plt.ylabel('SSE')\n",
        "    plt.show()\n",
        "\n",
        "elbow(bio_exists_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqwoY9DUiW9V"
      },
      "source": [
        "word_vectors = bio_exists_df.wv.to_list() \n",
        "\n",
        "def elbow(X):\n",
        "    sse = []\n",
        "\n",
        "    for i in range(10,100):\n",
        "        km = KMeans(n_clusters=i,algorithm='auto', random_state=42)\n",
        "        km.fit(word_vectors)\n",
        "        sse.append(km.inertia_)\n",
        "\n",
        "    plt.plot(range(10,100), sse, marker='o')\n",
        "    plt.xlabel('K')\n",
        "    plt.ylabel('SSE')\n",
        "    plt.show()\n",
        "\n",
        "elbow(bio_exists_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl2rL-l8QP_S"
      },
      "source": [
        "word_vectors = bio_exists_df.wv.to_list() \n",
        "\n",
        "def elbow(X):\n",
        "    sse = []\n",
        "\n",
        "    for i in range(20,41):\n",
        "        km = KMeans(n_clusters=i,algorithm='auto', random_state=42)\n",
        "        km.fit(word_vectors)\n",
        "        sse.append(km.inertia_)\n",
        "\n",
        "    plt.plot(range(20,41), sse, marker='o')\n",
        "    plt.xlabel('K')\n",
        "    plt.ylabel('SSE')\n",
        "    plt.show()\n",
        "\n",
        "elbow(bio_exists_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7BTDiuEWjnL"
      },
      "source": [
        "word_vectors = bio_exists_df.wv.to_list() \n",
        "\n",
        "def elbow(X):\n",
        "    sse = []\n",
        "\n",
        "    for i in range(41,61):\n",
        "        km = KMeans(n_clusters=i,algorithm='auto', random_state=42)\n",
        "        km.fit(word_vectors)\n",
        "        sse.append(km.inertia_)\n",
        "\n",
        "    plt.plot(range(41,61), sse, marker='o')\n",
        "    plt.xlabel('K')\n",
        "    plt.ylabel('SSE')\n",
        "    plt.show()\n",
        "\n",
        "elbow(bio_exists_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvvQOHNEYIuL"
      },
      "source": [
        "#svm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVmOPS0GW_zl"
      },
      "source": [
        "x = bio_exists_df['wv']\n",
        "y = bio_exists_df['category']\n",
        "\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiZglZOKXIgZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 나누기 - 6:2:2 비율\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)\n",
        "\n",
        "print(x_train.shape, x_val.shape, x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr9_w36aYR__"
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48PJ9HDvYX36"
      },
      "source": [
        "# linear SVM 학습하기\n",
        "linear_svm = SVC(kernel='linear')\n",
        "list_x_train = x_train.tolist()\n",
        "linear_svm.fit(list_x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIXVw7XNXSsS"
      },
      "source": [
        "# linear SVM accuracy 계산하기\n",
        "from sklearn.metrics import accuracy_score\n",
        "list_x_val = x_val.tolist()\n",
        "pred_val = linear_svm.predict(list_x_val)\n",
        "print(f\"accuracy:{accuracy_score(y_val, pred_val)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRQYTJYjYoIT"
      },
      "source": [
        "# 여러 가지 kernel을 사용해 SVM 학습하고 accuracy 계산하기\n",
        "kernels = ['poly','rbf','sigmoid']\n",
        "\n",
        "for kernel in kernels:\n",
        "    print(\"==========================================\") \n",
        "    model = SVC(kernel = kernel)\n",
        "    model.fit(list_x_train, y_train)\n",
        "    pred_val = model.predict(list_x_val)\n",
        "    print(f\"accuracy of {kernel}: {accuracy_score(y_val, pred_val)}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiO2jqnuYuDN"
      },
      "source": [
        "# 가장 좋다고 판단되는 SVM 모델로 test data 정확도 확인하기\n",
        "rbf_svm = SVC(kernel = 'rbf')\n",
        "rbf_svm.fit(list_x_train, y_train)\n",
        "list_x_test = x_test.tolist()\n",
        "pred_test = rbf_svm.predict(list_x_test)\n",
        "\n",
        "print(f'test accuracy of rbf SVM: {accuracy_score(y_test, pred_test)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hR-WJ4Z741I"
      },
      "source": [
        "bio_exists_df.to_excel('클러스터링3.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLIUpoFvHlFF"
      },
      "source": [
        "# Embedding & Clustering 시각화하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oW27OtwHm5D"
      },
      "source": [
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUWNlPUmHoM8"
      },
      "source": [
        "X = bio_exists_df['wv'].to_list()\n",
        "y = bio_exists_df['category'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN0OVWf1XM_4"
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1uEuc0hHqWg"
      },
      "source": [
        "차원축소 300->2차원으로 \n",
        "\n",
        "TSNE - 차원 축소 알고리즘 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JdHSAFZHuCU"
      },
      "source": [
        "import os.path\n",
        "import pickle\n",
        "\n",
        "tsne_filepath = 'tsne3000.pkl'\n",
        "\n",
        "# File Cache\n",
        "if not os.path.exists(tsne_filepath):\n",
        "    tsne = TSNE(random_state=42)\n",
        "    tsne_points = tsne.fit_transform(X)\n",
        "    with open(tsne_filepath, 'wb+') as f:\n",
        "        pickle.dump(tsne_points, f)\n",
        "else: # Cache Hits!\n",
        "    with open(tsne_filepath, 'rb') as f:\n",
        "        tsne_points = pickle.load(f)\n",
        "\n",
        "tsne_df = pd.DataFrame(tsne_points, index=range(len(X)), columns=['x_coord', 'y_coord'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ql2MTNsHvFs"
      },
      "source": [
        "tsne_df['user_bio'] = bio_exists_df['CONSULT_CONT'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHJT7vm1HwAP"
      },
      "source": [
        "tsne_df['cluster_no'] = y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXZGMiwSHxJc"
      },
      "source": [
        "\n",
        "tsne_df.sample(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XeHy5jgHzrB"
      },
      "source": [
        "from bokeh.plotting import figure, show, output_notebook\n",
        "from bokeh.models import HoverTool, ColumnDataSource, value\n",
        "from bokeh.palettes import brewer\n",
        "\n",
        "output_notebook()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0E88nOhH0lb"
      },
      "source": [
        "# Get the number of colors we'll need for the plot.\n",
        "colors = brewer[\"Spectral\"][len(tsne_df['cluster_no'].unique())]\n",
        "\n",
        "# Create a map between factor and color.\n",
        "colormap = {i: colors[i] for i in tsne_df['cluster_no'].unique()}\n",
        "\n",
        "# Create a list of colors for each value that we will be looking at.\n",
        "colors = [colormap[x] for x in tsne_df['cluster_no']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mKJiGNPH1lx"
      },
      "source": [
        "tsne_df['color'] = colors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SsLf8xMH2cM"
      },
      "source": [
        "# Bokeh Datasouce 만들기\n",
        "plot_data = ColumnDataSource(\n",
        "    data=tsne_df.to_dict(orient='list')\n",
        ")\n",
        "\n",
        "# Plot 만들기(배경)\n",
        "tsne_plot = figure(\n",
        "    # title='TSNE Twitter BIO Embeddings',\n",
        "    plot_width = 650,\n",
        "    plot_height = 650,\n",
        "    active_scroll='wheel_zoom',\n",
        "    output_backend=\"webgl\",\n",
        ")\n",
        "\n",
        "# 해당 Hover 툴팁 만들기\n",
        "tsne_plot.add_tools(\n",
        "    HoverTool(\n",
        "        tooltips='@user_bio'\n",
        "    )\n",
        ")\n",
        "\n",
        "tsne_plot.circle(\n",
        "    source=plot_data,\n",
        "    x='x_coord',\n",
        "    y='y_coord',\n",
        "    line_alpha=0.3, \n",
        "    fill_alpha=0.2,\n",
        "    size=10,\n",
        "    fill_color='color',\n",
        "    line_color='color',\n",
        ")\n",
        "\n",
        "# 각 값들 추가해주기 \n",
        "tsne_plot.title.text_font_size = value('16pt')\n",
        "tsne_plot.xaxis.visible = False\n",
        "tsne_plot.yaxis.visible = False\n",
        "tsne_plot.grid.grid_line_color = None\n",
        "tsne_plot.outline_line_color = None\n",
        "\n",
        "# 짠!\n",
        "show(tsne_plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb0FL5ZvH3tI"
      },
      "source": [
        "bio_exists_df[\n",
        "    bio_exists_df['category'] == 0\n",
        "][['CONSULT_CONT', 'category']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cgK3xN_H5cd"
      },
      "source": [
        "bio_exists_df[\n",
        "    bio_exists_df['category'] == 1\n",
        "][['CONSULT_CONT', 'category']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcUtwwOXH6YL"
      },
      "source": [
        "bio_exists_df[\n",
        "    bio_exists_df['category'] == 2\n",
        "][['CONSULT_CONT']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbdu69aEH9EH"
      },
      "source": [
        "bio_exists_df[\n",
        "    bio_exists_df['category'] == 3\n",
        "][['CONSULT_CONT', 'category']].head(5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}